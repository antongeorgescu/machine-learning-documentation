{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "7Yo9kOIZhs_-",
    "outputId": "3f32d013-28a3-4cb6-f53e-c52830bfec02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 13)\n",
      "(4898, 13)\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'color']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "REDWINE_PATH = \"../datasets/winequality-red.csv\"\n",
    "WHITEWINE_PATH = \"../datasets/winequality-white.csv\"\n",
    "\n",
    "# try different number of dimensions to see the effect in accuracy \n",
    "DIM_NO = 3\n",
    "\n",
    "# timer start\n",
    "import time \n",
    "start = time.time()\n",
    "\n",
    "# read red wine set of observations\n",
    "data_red = pd.read_csv(REDWINE_PATH,sep=',')\n",
    "data_red['color'] = 1 #redwine\n",
    "\n",
    "print(data_red.shape)\n",
    "\n",
    "# read white wine set of observations\n",
    "data_white = pd.read_csv(WHITEWINE_PATH,sep=',')\n",
    "data_white['color'] = 0 #whitewine\n",
    "\n",
    "print(data_white.shape)\n",
    "\n",
    "# merge the two sets in one\n",
    "data = data_red.merge(data_white, how='outer')\n",
    "fields = list(data.columns)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "D6lNNsPchtAP",
    "outputId": "a45f4b55-4049-421a-89eb-5a3e7c92acc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 'quality level' counts\n",
      "6    2836\n",
      "5    2138\n",
      "7    1079\n",
      "4     216\n",
      "8     193\n",
      "3      30\n",
      "9       5\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show the counts of all quality levels\n",
    "print(\"All 'quality level' counts\")\n",
    "print(data[\"quality\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "uQxTlPaUhtAe",
    "outputId": "079861fb-e4bb-4243-83dc-797976c2628a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 'quality level' counts\n",
      "6    2836\n",
      "5    2138\n",
      "7    1079\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# based on the \"quality histograms\" above, we will drop the ratings with low counts (we will keep only 5,6,7)\n",
    "data = data.drop(data[data.quality == 9].index)\n",
    "data = data.drop(data[data.quality == 8].index)\n",
    "data = data.drop(data[data.quality == 3].index)\n",
    "data = data.drop(data[data.quality == 4].index)\n",
    "\n",
    "# show the counts of selected quality levels\n",
    "print(\"Selected 'quality level' counts\")\n",
    "print(data[\"quality\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "1UGZhyd3htAo",
    "outputId": "23797d93-e195-4a3e-ccb1-ed270ae8d683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'color']\n"
     ]
    }
   ],
   "source": [
    "# split the data set in two: 1) color+features (observations)  2) quality (actuals)\n",
    "\n",
    "# select the outcomes\n",
    "y = data['quality']\n",
    "\n",
    "data = data.drop(columns=['quality'])\n",
    "\n",
    "# select the rows (observations)\n",
    "fields = list(data.columns)\n",
    "X = data[fields]\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KugTFGHZhtAx"
   },
   "source": [
    "We will use a dimensionality reduction through Principal Component Analysis to identify only a subset of the componenta that drive the dynamics of the dataset and have other correkated dimensions with the same direction of impact but less strength. We will retain only the components that altogether amount to at least 65% of the accummulated eigen values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "IXSqIIAMhtA0",
    "outputId": "6e2e0c95-a2a8-4fc0-f5f5-66e08525698d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "# now let's try to find the most important features by using PCA\n",
    "# first off drop off the remaining non-chemical features.\n",
    "data = data.drop(columns=['color'])\n",
    "fields = list(data.columns)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "OoJlRHsAhtA9",
    "outputId": "fa77d71d-209a-4589-c640-acebde780eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2812138845440715, 0.2253415991254009, 0.14112902232389624, 0.08521911434306068, 0.06594236811149971, 0.05517392086025881, 0.04717623443524541, 0.044540482246072564, 0.03069485623703559, 0.02061524915127792, 0.0029532686221809263]\n",
      "[28.12 50.65 64.76 73.28 79.87 85.39 90.11 94.56 97.63 99.69 99.99]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.22576744  0.41102896 -2.80018819 ... -0.01978679 -0.10947096\n",
      "   0.01529315]\n",
      " [ 3.22576744  0.41102896 -2.80018819 ... -0.01978679 -0.10947096\n",
      "   0.01529315]\n",
      " [ 3.0803782   1.1081831  -2.10888328 ...  0.45879586 -0.28024376\n",
      "  -0.03173186]\n",
      " ...\n",
      " [-0.5899141  -0.75755992  0.0849859  ...  0.1193659  -0.35116319\n",
      "   0.16074081]\n",
      " [-0.10690003 -3.59768863  0.08976857 ...  0.29385227  0.27203213\n",
      "   0.049235  ]\n",
      " [-0.53211027 -2.94597678  0.70908899 ...  0.22134967 -0.11090156\n",
      "   0.0057377 ]]\n"
     ]
    }
   ],
   "source": [
    "#refs: https://stackoverflow.com/questions/31909945/obtain-eigen-values-and-vectors-from-sklearn-pca\n",
    "#refs: https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "X = data[fields]\n",
    "X = scale(X)\n",
    "\n",
    "pca = PCA(n_components=11)\n",
    "pca.fit(X)\n",
    "\n",
    "eigvar= pca.explained_variance_ratio_\n",
    "print(eigvar.tolist())\n",
    "eigvar1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(eigvar1)\n",
    "\n",
    "dims = ('1','2','3','4','5','6','7','8','9','10','11')\n",
    "y_pos = np.arange(len(dims))\n",
    "\n",
    "plt.bar(y_pos, eigvar, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, dims)\n",
    "plt.ylabel('Contribution')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.title('Principal Components - Eigenvalues')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "XPca=pca.fit_transform(X)\n",
    "print(XPca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwZX27URhtBE"
   },
   "source": [
    "We will run now K_Nearest Neighbour algorithm (KNN) to create a \"prediction model\"\n",
    "KNN converges faster when features are scaled. If the model is senstive to magnitudes its generally a good idea to scale so one feature doesnâ€™t get more influence than the other(in terms of scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dim1      Dim2      Dim3      Dim4      Dim5      Dim6      Dim7  \\\n",
      "0     3.225767  0.411029 -2.800188 -0.852343  0.199122 -0.265351 -0.194558   \n",
      "1     3.225767  0.411029 -2.800188 -0.852343  0.199122 -0.265351 -0.194558   \n",
      "2     3.080378  1.108183 -2.108883 -0.931437 -1.276995  1.731359 -0.029815   \n",
      "3     3.114580  0.863640 -1.804274 -0.919626 -0.733310  0.897621  0.142934   \n",
      "4     1.652820  2.021409  2.608647 -0.267437  0.594091 -0.826626 -0.477675   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "6048  0.054442 -1.986983  0.189462  0.191258 -0.006353 -0.571107  0.417440   \n",
      "6049 -1.881734  0.529466 -0.400523  0.173811 -0.529238  0.209778 -0.331691   \n",
      "6050 -0.589914 -0.757560  0.084986 -0.989145 -1.230461 -0.387528  1.348390   \n",
      "6051 -0.106900 -3.597689  0.089769 -0.063209  0.225839 -0.182203 -0.553685   \n",
      "6052 -0.532110 -2.945977  0.709089 -0.431966  0.087337 -0.895315 -0.435394   \n",
      "\n",
      "          Dim8      Dim9     Dim10     Dim11  \n",
      "0    -0.621275 -0.019787 -0.109471  0.015293  \n",
      "1    -0.621275 -0.019787 -0.109471  0.015293  \n",
      "2    -0.481320  0.458796 -0.280244 -0.031732  \n",
      "3    -0.355281  0.306244 -0.087118  0.040779  \n",
      "4    -1.093898 -0.558565  0.112130 -0.106979  \n",
      "...        ...       ...       ...       ...  \n",
      "6048  0.060101 -0.058787 -0.101123 -0.011137  \n",
      "6049 -0.348985  0.114367 -0.488917 -0.082722  \n",
      "6050 -0.762668  0.119366 -0.351163  0.160741  \n",
      "6051  0.529586  0.293852  0.272032  0.049235  \n",
      "6052  0.142622  0.221350 -0.110902  0.005738  \n",
      "\n",
      "[6053 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "XPcaDf = pd.DataFrame(data = XPca,columns = ['Dim1','Dim2','Dim3','Dim4','Dim5','Dim6','Dim7','Dim8','Dim9','Dim10','Dim11'])\n",
    "print(XPcaDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dim1      Dim2      Dim3\n",
      "0     3.225767  0.411029 -2.800188\n",
      "1     3.225767  0.411029 -2.800188\n",
      "2     3.080378  1.108183 -2.108883\n",
      "3     3.114580  0.863640 -1.804274\n",
      "4     1.652820  2.021409  2.608647\n",
      "...        ...       ...       ...\n",
      "6048  0.054442 -1.986983  0.189462\n",
      "6049 -1.881734  0.529466 -0.400523\n",
      "6050 -0.589914 -0.757560  0.084986\n",
      "6051 -0.106900 -3.597689  0.089769\n",
      "6052 -0.532110 -2.945977  0.709089\n",
      "\n",
      "[6053 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "if (DIM_NO == 8):\n",
    "    # since the first 5 dimensions amount to 80% of data variability, drop the dimensions >=6\n",
    "    XPcaDf = XPcaDf.drop('Dim9', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim10', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim11', 1)\n",
    "elif (DIM_NO == 7):\n",
    "    # since the first 5 dimensions amount to 80% of data variability, drop the dimensions >=6\n",
    "    XPcaDf = XPcaDf.drop('Dim8', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim9', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim10', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim11', 1)\n",
    "elif (DIM_NO == 6):\n",
    "    # since the first 5 dimensions amount to 80% of data variability, drop the dimensions >=6\n",
    "    XPcaDf = XPcaDf.drop('Dim7', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim8', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim9', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim10', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim11', 1)\n",
    "elif (DIM_NO == 5):\n",
    "    # since the first 5 dimensions amount to 80% of data variability, drop the dimensions >=6\n",
    "    XPcaDf = XPcaDf.drop('Dim6', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim7', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim8', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim9', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim10', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim11', 1)\n",
    "elif (DIM_NO == 4):\n",
    "    XPcaDf = XPcaDf.drop('Dim5', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim6', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim7', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim8', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim9', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim10', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim11', 1)\n",
    "elif (DIM_NO == 3):\n",
    "    XPcaDf = XPcaDf.drop('Dim4', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim5', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim6', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim7', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim8', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim9', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim10', 1)\n",
    "    XPcaDf = XPcaDf.drop('Dim11', 1)\n",
    "\n",
    "\n",
    "print(XPcaDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FtGH1rohtBG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Dim1_scaled', 'Dim2_scaled', 'Dim3_scaled'], dtype='object')\n",
      "[-7.51275980e-17 -3.75637990e-17  2.81728493e-17]\n",
      "[1.75879298 1.57440706 1.24596117]\n"
     ]
    }
   ],
   "source": [
    "# apply normalization to the eigenspace\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DO_STANDARDSCALER = True\n",
    "scaler = None\n",
    "fields = list(XPcaDf.columns)\n",
    "if DO_STANDARDSCALER:\n",
    "    scaler = StandardScaler().fit(XPcaDf)\n",
    "    X = scaler.transform(XPcaDf)\n",
    "\n",
    "    X = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\n",
    "    print(X.columns) #scaled columns\n",
    "\n",
    "    print(scaler.mean_)\n",
    "    print(scaler.scale_)\n",
    "\n",
    "else:\n",
    "    scaler = MinMaxScaler().fit(XPcaDf)\n",
    "    print(scaler.data_max_)\n",
    "    print(scaler.data_min_)\n",
    "\n",
    "    X = scaler.transform(XPcaDf)\n",
    "\n",
    "    X = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\n",
    "    print(X.columns) #scaled columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QiqtfXslhtBQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dim1      Dim2      Dim3\n",
      "4744 -1.164749 -1.598111  1.683167\n",
      "647   2.217867  3.376573  3.108731\n",
      "2173 -1.476531 -0.120830  1.065960\n",
      "2107 -1.930873  0.707145 -1.986370\n",
      "799   3.124795  0.135425 -2.631479\n",
      "...        ...       ...       ...\n",
      "3413 -0.112948  0.256061 -0.411985\n",
      "174   1.131916  1.597523  1.407788\n",
      "1518 -2.756565  3.058433 -0.575631\n",
      "1192  2.618331 -0.562390 -1.972057\n",
      "4638 -1.132679  0.773428 -1.466547\n",
      "\n",
      "[1816 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we will split the data in training (70%) and testing (30%) whihc is the usual ratio\n",
    "fields = list(XPcaDf.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(XPcaDf, y, test_size=0.3, random_state=10)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8rjjKgUhtBX",
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unterminated string (<ipython-input-11-31ca769dfb9c>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-31ca769dfb9c>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}, {row['Dim4']}, {row['Dim5']}, {row['Dim6']}, {row['Dim7]}\")\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unterminated string\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate KNN learning model (k=15)\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "# predict the wine rankings for the test data set\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#print(print('predict\\tactual\\tDim1_scaled,','Dim2_scaled,','Dim3_scaled,','Dim4_scaled'))\n",
    "\n",
    "if (DIM_NO == 8):\n",
    "    print(print('predict\\tactual\\tDim1,','Dim2,','Dim3,','Dim4','Dim5','Dim6','Dim7','Dim8'))\n",
    "    i=0\n",
    "    for index,row in X_test.iterrows():\n",
    "        print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}, {row['Dim4']}, {row['Dim5']}, {row['Dim6']}, {row['Dim7']}, {row['Dim8']}\")\n",
    "        i=i+1\n",
    "elif (DIM_NO == 7):\n",
    "    print(print('predict\\tactual\\tDim1,','Dim2,','Dim3,','Dim4','Dim5','Dim6','Dim7'))\n",
    "    i=0\n",
    "    for index,row in X_test.iterrows():\n",
    "        print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}, {row['Dim4']}, {row['Dim5']}, {row['Dim6']}, {row['Dim7]}\")\n",
    "        i=i+1\n",
    "elif (DIM_NO == 6):\n",
    "    print(print('predict\\tactual\\tDim1,','Dim2,','Dim3,','Dim4','Dim5','Dim6'))\n",
    "    i=0\n",
    "    for index,row in X_test.iterrows():\n",
    "        print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}, {row['Dim4']}, {row['Dim5']}, {row['Dim6']}\")\n",
    "        i=i+1\n",
    "elif (DIM_NO == 5):\n",
    "    print(print('predict\\tactual\\tDim1,','Dim2,','Dim3,','Dim4','Dim5'))\n",
    "    i=0\n",
    "    for index,row in X_test.iterrows():\n",
    "        print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}, {row['Dim4']}, {row['Dim5']}\")\n",
    "        i=i+1\n",
    "elif (DIM_NO == 4):\n",
    "    print(print('predict\\tactual\\tDim1,','Dim2,','Dim3,','Dim4'))\n",
    "    i=0\n",
    "    for index,row in X_test.iterrows():\n",
    "        print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}, {row['Dim4']}\")\n",
    "        i=i+1\n",
    "elif (DIM_NO == 3):\n",
    "    print(print('predict\\tactual\\tDim1,','Dim2,','Dim3'))\n",
    "    i=0\n",
    "    for index,row in X_test.iterrows():\n",
    "        print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['Dim1']}, {row['Dim2']},{row['Dim3']}\")\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKgNCxarhtBe"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "# Calculate the accuracy of prediction\n",
    "metrics = list()\n",
    "cm = dict()\n",
    "\n",
    "# Precision, recall, f-score from the multi-class support function\n",
    "precision, recall, fscore, _ = score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "metrics.append(pd.Series({'precision':precision, 'recall':recall, \n",
    "                          'fscore':fscore, 'accuracy':accuracy}, \n",
    "                         name='Model'))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Last, the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g');\n",
    "plt.title('Confusion matrix of the KNN classifier (use PCA)')    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OxOeKHEOhtBl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# another way to calculate the prediction accuracy by using a KNN built-in method\n",
    "mean_accuracy = knn.score(X_test,y_test)\n",
    "print(mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jjXru8nhtBt"
   },
   "source": [
    "We will try now to get the quality prediction for a new wine that comes with the full sets of parameters:\n",
    "'color', 'fixed acidity','volatile acidity','citric acid','residual sugar','chlorides', 'free sulfur dioxide','total sulfur dioxide', 'density', 'pH','sulphates','alcohol'\n",
    "\n",
    "Examples:\n",
    "    red wine:          [1,7.4,0.7,0,1.9,0.76,11,34,0.9978,3.51,0.56,9.4]\n",
    "    white wine:        [0,6.6,0.17,0.38,1.5,0.032,28,112,0.9914,3.25,0.55,11.4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qChAJrcPhtBw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X0 = [[1,7.4,0.7,0,1.9,0.76,11,34,0.9978,3.51,0.56,9.4],[0,6.6,0.17,0.38,1.5,0.032,28,112,0.9914,3.25,0.55,11.4]]\n",
    "dfX=pd.DataFrame(X0)\n",
    "\n",
    "print(\"===Wines (new data)=====================================================\")\n",
    "\n",
    "dfX.columns = ['color', 'fixed acidity','volatile acidity','citric acid','residual sugar','chlorides', 'free sulfur dioxide','total sulfur dioxide', 'density', 'pH','sulphates','alcohol']\n",
    "dfX.index = ['red_wine_0','white_wine_0']\n",
    "print(dfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qChAJrcPhtBw"
   },
   "outputs": [],
   "source": [
    "inxs = dfX.index\n",
    "dfX = dfX.drop(columns=['color'])\n",
    "\n",
    "#transpose this set into eigenspace\n",
    "XPcaDf0 = pca.transform(dfX)\n",
    "XPcaDf0 = pd.DataFrame(data = XPcaDf0,columns = ['Dim1','Dim2','Dim3','Dim4','Dim5','Dim6','Dim7','Dim8','Dim9','Dim10','Dim11'])\n",
    "\n",
    "if (DIM_NO == 8):\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim9', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim10', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim11', 1)\n",
    "elif (DIM_NO == 7):\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim8', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim9', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim10', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim11', 1)\n",
    "elif (DIM_NO == 6):\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim7', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim8', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim9', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim10', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim11', 1)\n",
    "elif (DIM_NO == 5):\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim6', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim7', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim8', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim9', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim10', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim11', 1)\n",
    "elif (DIM_NO == 4):\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim5', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim6', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim7', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim8', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim9', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim10', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim11', 1)\n",
    "elif (DIM_NO == 3):\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim4', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim5', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim6', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim7', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim8', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim9', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim10', 1)\n",
    "    XPcaDf0 = XPcaDf0.drop('Dim11', 1)\n",
    "\n",
    "print(XPcaDf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qChAJrcPhtBw"
   },
   "outputs": [],
   "source": [
    "# apply normalization to the eigenspace\n",
    "XPcaDf0 = scaler.transform(XPcaDf0)\n",
    "print(XPcaDf0)\n",
    "y0_pred = knn.predict(XPcaDf0)\n",
    "\n",
    "print(\"\\n===Predicted Quality====================================================\")\n",
    "print(f\"{inxs[0]}:\\t{y0_pred[0]}\")\n",
    "print(f\"{inxs[1]}:\\t{y0_pred[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf3jG25xhtB2"
   },
   "outputs": [],
   "source": [
    "# end timer\n",
    "\n",
    "end = time.time() \n",
    "print(end - start)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WineQualityAnalysis_KNN_PCA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bitc0556de680de4c0aae08a6e63bbd036c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
